{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arabic-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def data_preprocess(path):\n",
    "    # Import the dataset\n",
    "    data = pd.read_csv(path)\n",
    "    # Split the urls by /\n",
    "    split = data['URL'].str.split('/', expand=True)\n",
    "    # Drop the first column since there was a double slash\n",
    "    split.drop([1], axis=1, inplace=True)\n",
    "    # get rid of the 'www.'\n",
    "    split[2] = split[2].map(lambda x: x.lstrip('www.'))\n",
    "    # Create a column with the number of '.' in the url\n",
    "    data['num_domain_periods'] = split[2].str.count('\\.')\n",
    "    # Create a column with the total length of the url\n",
    "    data['domain_length'] = split[2].str.replace('\\.', '', regex=True).str.len()\n",
    "    # Create a column with the number of terms in the domain\n",
    "    data['num_domain_terms'] = split[2].str.split('\\.').str.len()\n",
    "    # Create a blacklist of sensitive words\n",
    "    sensitive_words = ['confirm' 'account',\n",
    "    'bank', 'secure', 'login', 'signin', 'register', 'update', 'sign-in', 'verify']\n",
    "    # Join all of the words in the blacklist with '|'\n",
    "    sensitive = '|'.join(sensitive_words)\n",
    "    # Create a column of whether a given url contains sensitive words\n",
    "    data['Has_Sensitive_words'] = 0\n",
    "    data.loc[data.URL.str.contains(sensitive), 'Has_Sensitive_words'] = 1\n",
    "    # Create a column of whether a given url contains an IP address\n",
    "    data['Has_IP'] = 0\n",
    "    data.loc[data.URL.str.contains('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}'), 'Has_IP'] = 1\n",
    "    # Create a column that contains the number of periods in the url not including the last three\n",
    "    data['Num_Periods'] = data['URL'].str.count('\\.')-3\n",
    "    # Create a blacklist of sensitive characters\n",
    "    suspicious = ['-', '@', '%']\n",
    "    # Join all of the words in the blacklist with '|'\n",
    "    suspicious_char = '|'.join(suspicious)\n",
    "    # Create a column of whether a given url contains suspicious characters\n",
    "    data['Has_sus_char'] = data.URL.str.replace(r':|\\.|/', '', regex=True).str.contains(suspicious_char)\n",
    "    data['Has_sus_char'] = data['Has_sus_char'].astype(int)\n",
    "    # Create a column for the length of the URL\n",
    "    data['URL_Length'] = data.URL.str.len()\n",
    "    # Create a column with the number of the slashes in the URL\n",
    "    data['num_slashes'] = data.URL.str.count('/')\n",
    "    # Create a blacklist for suspicious files\n",
    "    files_list = ['.php','.exe','.py','.doc', '.js', '.vb', '.pdf', '.bat', '.dll', '.tmp', '.msi', '.msp', '.ps[12c]', '.lnk', '.inf', 'cmd', 'asp', 'jsp', 'cgi']\n",
    "    # Join all of the words in the blacklist with '|'\n",
    "    files = '|'.join(files_list)\n",
    "    # Create a column of whether a given url contains suspicious_files\n",
    "    data['sus_files'] = 0\n",
    "    data.loc[data.URL.str.contains(files, case=False), 'sus_files'] = 1\n",
    "    # Reorder columns for future column indexing purposes\n",
    "    cols_at_end = ['Label']\n",
    "    data = data[[c for c in data if c not in cols_at_end] \n",
    "            + [c for c in cols_at_end if c in data]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vulnerable-shore",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c7544dc13e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Load the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtesting_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Get the x and y columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "#splitting training and testing data\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier as GBClf\n",
    "\n",
    "# Load the training data\n",
    "training = data_preprocess('./Training Data/Phishing_Mitre_Dataset_Summer_of_AI.csv')\n",
    "# Define the target column\n",
    "y_cols = training[\"Label\"]\n",
    "# Define the features, exclusing the target and URL \n",
    "x_cols = training.drop(columns=[\"Label\", 'URL'])\n",
    "# Split the data into a 80% training - 20% test split\n",
    "\n",
    "gbclf = GBClf(random_state=0, max_depth=6, n_estimators= 100, min_child_weight=1, learning_rate=0.200,\n",
    "             use_label_encoder=False, eval_metric='auc').fit(x_cols, y_cols)\n",
    "\n",
    "# Load the test set\n",
    "testing_path = ''\n",
    "testing = data_preprocess(path)\n",
    "\n",
    "# Get the x and y columns\n",
    "test_x_col = testing.drop(columns=[\"Label\", 'URL'])\n",
    "test_y_col = testing[\"Label\"]\n",
    "\n",
    "# Predict on the testing set\n",
    "labeled_pred_gbclf = gbclf.predict(test_x_col)\n",
    "\n",
    "# Assess model performance\n",
    "print('Gradient Boosting Model')\n",
    "print(f'F1 Score: {f1(test_y_col, labeled_pred_gbclf)}')\n",
    "print(f'AUC Score: {auc(test_y_col, labeled_pred_gbclf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-storage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inst_414",
   "language": "python",
   "name": "inst_414"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
