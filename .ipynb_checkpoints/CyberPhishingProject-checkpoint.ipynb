{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorporate-daily",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "checked-retreat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_age(months)</th>\n",
       "      <th>expiry_age(months)</th>\n",
       "      <th>update_age(days)</th>\n",
       "      <th>URL</th>\n",
       "      <th>num_domain_periods</th>\n",
       "      <th>domain_length</th>\n",
       "      <th>num_domain_terms</th>\n",
       "      <th>Has_Sensitive_words</th>\n",
       "      <th>Has_IP</th>\n",
       "      <th>Num_Periods</th>\n",
       "      <th>Has_sus_char</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>num_slashes</th>\n",
       "      <th>sus_files</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>http://account-google-com.ngate.my/c44cca40176...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>16</td>\n",
       "      <td>663</td>\n",
       "      <td>http://www.coffeespecialties.com/...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>http://black.pk/wp-content/2013/04/bp.postale/...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198</td>\n",
       "      <td>6</td>\n",
       "      <td>186</td>\n",
       "      <td>http://atomicsoda.com/manutd...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240</td>\n",
       "      <td>24</td>\n",
       "      <td>1684</td>\n",
       "      <td>http://bostoncoffeecake.com/...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "      <td>http://aridfoods.com/V4/MGen/F97a8a294cf7c5e90...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>http://www.mazda.co.jp/...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>http://www.fotografaemsaopaulo.com.br/wp-admin...</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>http://agenda.wehrensarl.ch/libraries/joomla/h...</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>172</td>\n",
       "      <td>68</td>\n",
       "      <td>745</td>\n",
       "      <td>http://www.waterfrontrecords.com/...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4799 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      create_age(months)  expiry_age(months)  update_age(days)  \\\n",
       "0                     -1                  -1                -1   \n",
       "1                    212                  16               663   \n",
       "2                     -1                  -1                -1   \n",
       "3                    198                   6               186   \n",
       "4                    240                  24              1684   \n",
       "...                  ...                 ...               ...   \n",
       "4794                  52                   8               118   \n",
       "4795                  -1                  -1                -1   \n",
       "4796                  -1                  -1                -1   \n",
       "4797                  -1                  -1                -1   \n",
       "4798                 172                  68               745   \n",
       "\n",
       "                                                    URL  num_domain_periods  \\\n",
       "0     http://account-google-com.ngate.my/c44cca40176...                   2   \n",
       "1                  http://www.coffeespecialties.com/...                   1   \n",
       "2     http://black.pk/wp-content/2013/04/bp.postale/...                   1   \n",
       "3                       http://atomicsoda.com/manutd...                   1   \n",
       "4                       http://bostoncoffeecake.com/...                   1   \n",
       "...                                                 ...                 ...   \n",
       "4794  http://aridfoods.com/V4/MGen/F97a8a294cf7c5e90...                   1   \n",
       "4795                         http://www.mazda.co.jp/...                   2   \n",
       "4796  http://www.fotografaemsaopaulo.com.br/wp-admin...                   2   \n",
       "4797  http://agenda.wehrensarl.ch/libraries/joomla/h...                   2   \n",
       "4798               http://www.waterfrontrecords.com/...                   1   \n",
       "\n",
       "      domain_length  num_domain_terms  Has_Sensitive_words  Has_IP  \\\n",
       "0                25                 3                    0       0   \n",
       "1                20                 2                    0       0   \n",
       "2                 7                 2                    0       0   \n",
       "3                13                 2                    0       0   \n",
       "4                19                 2                    0       0   \n",
       "...             ...               ...                  ...     ...   \n",
       "4794             12                 2                    0       0   \n",
       "4795              9                 3                    0       0   \n",
       "4796             24                 3                    0       0   \n",
       "4797             18                 3                    0       0   \n",
       "4798             19                 2                    0       0   \n",
       "\n",
       "      Num_Periods  Has_sus_char  URL_Length  num_slashes  sus_files  Label  \n",
       "0               2             1          70            3          0      1  \n",
       "1               2             0          36            3          0      0  \n",
       "2               2             1          73            7          0      1  \n",
       "3               1             0          31            3          0      0  \n",
       "4               1             0          31            3          0      0  \n",
       "...           ...           ...         ...          ...        ...    ...  \n",
       "4794            1             0          73            6          0      1  \n",
       "4795            3             0          26            3          0      0  \n",
       "4796            3             1          73            6          1      1  \n",
       "4797            2             0          73            8          0      1  \n",
       "4798            2             0          36            3          0      0  \n",
       "\n",
       "[4799 rows x 15 columns]"
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the dataset\n",
    "training = pd.read_csv('./Training Data/Phishing_Mitre_Dataset_Summer_of_AI.csv')\n",
    "# Split the urls by /\n",
    "split = training['URL'].str.split('/', expand=True)\n",
    "# Drop the first column since there was a double slash\n",
    "split.drop([1], axis=1, inplace=True)\n",
    "# get rid of the 'www.'\n",
    "split[2] = split[2].map(lambda x: x.lstrip('www.'))\n",
    "# Create a column with the number of '.' in the url\n",
    "training['num_domain_periods'] = split[2].str.count('\\.')\n",
    "# Create a column with the total length of the url\n",
    "training['domain_length'] = split[2].str.replace('\\.', '', regex=True).str.len()\n",
    "# Create a column with the number of terms in the domain\n",
    "training['num_domain_terms'] = split[2].str.split('\\.').str.len()\n",
    "# Create a blacklist of sensitive words\n",
    "sensitive_words = ['confirm' 'account',\n",
    "'bank', 'secure', 'login', 'signin', 'register', 'update', 'sign-in', 'verify']\n",
    "# Join all of the words in the blacklist with '|'\n",
    "sensitive = '|'.join(sensitive_words)\n",
    "# Create a column of whether a given url contains sensitive words\n",
    "training['Has_Sensitive_words'] = 0\n",
    "training.loc[training.URL.str.contains(sensitive), 'Has_Sensitive_words'] = 1\n",
    "# Create a column of whether a given url contains an IP address\n",
    "training['Has_IP'] = 0\n",
    "training.loc[training.URL.str.contains('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}'), 'Has_IP'] = 1\n",
    "# Create a column that contains the number of periods in the url not including the last three\n",
    "training['Num_Periods'] = training['URL'].str.count('\\.')-3\n",
    "# Create a blacklist of sensitive characters\n",
    "suspicious = ['-', '@', '%']\n",
    "# Join all of the words in the blacklist with '|'\n",
    "suspicious_char = '|'.join(suspicious)\n",
    "# Create a column of whether a given url contains suspicious characters\n",
    "training['Has_sus_char'] = training.URL.str.replace(r':|\\.|/', '', regex=True).str.contains(suspicious_char)\n",
    "training['Has_sus_char'] = training['Has_sus_char'].astype(int)\n",
    "# Create a column for the length of the URL\n",
    "training['URL_Length'] = training.URL.str.len()\n",
    "# Create a column with the number of the slashes in the URL\n",
    "training['num_slashes'] = training.URL.str.count('/')\n",
    "# Create a blacklist for suspicious files\n",
    "files_list = ['.php','.exe','.py','.doc', '.js', '.vb', '.pdf', '.bat', '.dll', '.tmp', '.msi', '.msp', '.ps[12c]', '.lnk', '.inf', 'cmd', 'asp', 'jsp', 'cgi']\n",
    "# Join all of the words in the blacklist with '|'\n",
    "files = '|'.join(files_list)\n",
    "# Create a column of whether a given url contains suspicious_files\n",
    "training['sus_files'] = 0\n",
    "training.loc[training.URL.str.contains(files, case=False), 'sus_files'] = 1\n",
    "# Reorder columns for future column indexing purposes\n",
    "cols_at_end = ['Label']\n",
    "training = training[[c for c in training if c not in cols_at_end] \n",
    "        + [c for c in cols_at_end if c in training]]\n",
    "training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-freeze",
   "metadata": {},
   "source": [
    "# Cross Validation and Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "matched-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting training and testing data\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler as SScaler\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.tree import DecisionTreeClassifier as DTClf\n",
    "from sklearn.ensemble import RandomForestClassifier as rfClfs\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNClf\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.model_selection import ParameterGrid as PGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier as GBClf\n",
    "# Define the target column\n",
    "y_col = training[\"Label\"]\n",
    "# Define the features, exclusing the target and URL \n",
    "x_cols = training.drop(columns=[\"Label\", 'URL'])\n",
    "# Split the data into a 80% training - 20% test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_cols, y_col, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "effective-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define parameters:\n",
    "param_grid_all = {}\n",
    "# Define the parameters for the logistic regression model\n",
    "param_grid_all['logistic_regression'] = PGrid({'C' : [.01, .5, 1, 5, 10, 100, 1000], \n",
    "                                              'max_iter' : [25000]})\n",
    "# Define the parameters for the decision tree model\n",
    "param_grid_all['decision_tree'] = PGrid({'max_depth' : [1, 2, 4, 8], \n",
    "                                         'min_samples_split' : [2, 30, 100]})\n",
    "# Define the parameters for the random forest model\n",
    "param_grid_all['random_forest'] = PGrid({'n_estimators': [10,50,100,200,500],\n",
    "                                        'max_depth' : [1,2,4,8], 'min_samples_split' : [2, 30, 100]})\n",
    "# Define the parameters for the gradient boosing model\n",
    "param_grid_all['gradient_boosting'] = PGrid({'learning_rate' : [0.1, 0.2, 0.5],\n",
    "                                         'n_estimators': [50,100,200],\n",
    "                                         'max_depth' : [6,4,8], 'min_child_weight' : [1,3,5,20,30,100],\n",
    "                                             'use_label_encoder':[False], 'eval_metric': ['auc']})\n",
    "# Define the parameters for the k-nearest neighbors model\n",
    "param_grid_all['k-nearest_neighbors'] = PGrid({'n_neighbors' : [4,5,6,7,8,9,10], 'weights' : ['uniform']})\n",
    "\n",
    "# Define the parameters for the support vector machine model\n",
    "param_grid_all['support_vector_machine'] = PGrid({'C' : [.01, .5, 1, 5, 10, 100, 1000], \n",
    "                                                 'probability' : [True]})\n",
    "\n",
    "# Define the parameters for the MLP neural network model\n",
    "param_grid_all['mlp_neural_network'] = PGrid({'hidden_layer_sizes' : [20,50,100,150],\n",
    "                                              'solver' : ['lbfgs', 'adam'], 'max_iter' : [25000]})\n",
    "\n",
    "# Define the classes for the models\n",
    "models = {\n",
    "         'logistic_regression' : LR,\n",
    "         'decision_tree' : DTClf,\n",
    "         'random_forest' : rfClfs,\n",
    "         'gradient_boosting' : GBClf,\n",
    "         'k-nearest_neighbors' : KNClf,\n",
    "         'support_vector_machine' : SvmClf,\n",
    "         'mlp_neural_network' : MlpClf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "greek-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing logistic_regression\n",
      "Processed logistic_regression in 5.4265642166137695 seconds.\n",
      "Processing decision_tree\n",
      "Processed decision_tree in 0.7151260375976562 seconds.\n",
      "Processing random_forest\n",
      "Processed random_forest in 110.1280300617218 seconds.\n",
      "Processing gradient_boosting\n",
      "Processed gradient_boosting in 275.35215306282043 seconds.\n",
      "Processing k-nearest_neighbors\n",
      "Processed k-nearest_neighbors in 0.9832398891448975 seconds.\n"
     ]
    }
   ],
   "source": [
    "'''The following code performs 5 fold cross validation and collects data about the optimal \n",
    "hyper-parameter combinations.'''\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "inner_cv = StratifiedKFold(n_splits=5, random_state=2, shuffle=True)\n",
    "\n",
    "transform_feature_names = x_cols.filter(regex='length|num|age', axis=1).columns\n",
    "feature_names = x_cols.columns\n",
    "\n",
    "results_dict = {}\n",
    "for model_name, the_model in models.items():\n",
    "    print(f'Processing {model_name}')\n",
    "    start = time.time()\n",
    "    results_dict[model_name] = []\n",
    "    fold = 0\n",
    "    for train_ix, test_ix in outer_cv.split(X=x_cols, y=y_col):\n",
    "        fold += 1\n",
    "        X_train = training.iloc[train_ix][feature_names].copy()\n",
    "        X_test = training.iloc[test_ix][feature_names].copy()\n",
    "        y_train = training.iloc[train_ix]['Label']\n",
    "        y_test = training.iloc[test_ix]['Label']\n",
    "\n",
    "        ss = SScaler()\n",
    "        ss = ss.fit(X_train[transform_feature_names])\n",
    "        X_train.loc[:, transform_feature_names] = ss.transform(X_train[transform_feature_names])\n",
    "        X_test.loc[:, transform_feature_names] = ss.transform(X_test[transform_feature_names])\n",
    "\n",
    "        for pg in param_grid_all[model_name]:\n",
    "            estimator = the_model(**pg)                \n",
    "            estimator = estimator.fit(X_train, y_train)\n",
    "            auc_score = auc(y_test, estimator.predict_proba(X_test)[:,1])\n",
    "            results_dict[model_name].append(pd.DataFrame([pg]))\n",
    "            results_dict[model_name][-1]['fold'] = fold\n",
    "            results_dict[model_name][-1]['auc'] = auc_score\n",
    "    print(f'Processed {model_name} in {time.time()-start} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-invitation",
   "metadata": {},
   "source": [
    "# Decision Tree Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-richmond",
   "metadata": {},
   "source": [
    "### Display K-fold Cross Validation for Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "clean-clark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>fold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.972553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.969252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.968854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.968497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.827370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.827370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.825819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.825819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.825819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  fold       auc\n",
       "0           8                100     2  0.972740\n",
       "0           8                 30     5  0.972553\n",
       "0           8                100     5  0.969252\n",
       "0           8                100     4  0.968854\n",
       "0           8                 30     2  0.968497\n",
       "..        ...                ...   ...       ...\n",
       "0           1                  2     2  0.827370\n",
       "0           1                100     2  0.827370\n",
       "0           1                  2     3  0.825819\n",
       "0           1                 30     3  0.825819\n",
       "0           1                100     3  0.825819\n",
       "\n",
       "[60 rows x 4 columns]"
      ]
     },
     "execution_count": 933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_results = pd.concat(results_dict['decision_tree'])\n",
    "decision_tree_results.sort_values(by='auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "progressive-celtic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model\n",
      "F1 Score: 0.8995901639344263\n",
      "AUC Score: 0.8978486221805491\n"
     ]
    }
   ],
   "source": [
    "dtclf = DTClf(random_state=0, max_depth=8, min_samples_split=100).fit(x_train, y_train)\n",
    "labeled_pred_dtclf = dtclf.predict(x_test)\n",
    "print('Decision Tree Model')\n",
    "print(f'F1 Score: {f1(y_test, labeled_pred_dtclf)}')\n",
    "print(f'AUC Score: {auc(y_test, labeled_pred_dtclf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-accused",
   "metadata": {},
   "source": [
    "# Logistic Regession Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-publisher",
   "metadata": {},
   "source": [
    "### Display K-fold Cross Validation for Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "sudden-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>fold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.963419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.963001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>25000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.962713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.962526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>25000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.957200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.955208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.955178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.955165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.953770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.953621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>25000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.951961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>25000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.942778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C  max_iter  fold       auc\n",
       "0  1000.00     25000     4  0.964649\n",
       "0   100.00     25000     4  0.964618\n",
       "0    10.00     25000     4  0.964378\n",
       "0     5.00     25000     4  0.964304\n",
       "0     1.00     25000     4  0.963419\n",
       "0     0.50     25000     2  0.963001\n",
       "0     0.50     25000     4  0.962713\n",
       "0     1.00     25000     2  0.962526\n",
       "0     5.00     25000     5  0.962178\n",
       "0     1.00     25000     5  0.962152\n",
       "0    10.00     25000     5  0.962121\n",
       "0   100.00     25000     5  0.962113\n",
       "0  1000.00     25000     5  0.962091\n",
       "0     0.50     25000     5  0.962034\n",
       "0     5.00     25000     2  0.961829\n",
       "0    10.00     25000     2  0.961641\n",
       "0  1000.00     25000     2  0.961449\n",
       "0   100.00     25000     2  0.961449\n",
       "0     1.00     25000     1  0.958590\n",
       "0     0.50     25000     1  0.958399\n",
       "0  1000.00     25000     1  0.958316\n",
       "0   100.00     25000     1  0.958268\n",
       "0     5.00     25000     1  0.958220\n",
       "0    10.00     25000     1  0.958154\n",
       "0     0.01     25000     2  0.957200\n",
       "0     0.01     25000     1  0.955722\n",
       "0    10.00     25000     3  0.955208\n",
       "0   100.00     25000     3  0.955178\n",
       "0  1000.00     25000     3  0.955165\n",
       "0     5.00     25000     3  0.954999\n",
       "0     1.00     25000     3  0.954319\n",
       "0     0.50     25000     3  0.953770\n",
       "0     0.01     25000     5  0.953621\n",
       "0     0.01     25000     4  0.951961\n",
       "0     0.01     25000     3  0.942778"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_results = pd.concat(results_dict['logistic_regression'])\n",
    "logistic_regression_results.sort_values(by='auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "surrounded-uniform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model\n",
      "F1 Score: 0.9090909090909091\n",
      "AUC Score: 0.9060009376465074\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=25000, C=1000.0).fit(x_train, y_train)\n",
    "labeled_pred_lr = clf.predict(x_test)\n",
    "print('Logistic Regression Model')\n",
    "print(f'F1 Score: {f1(y_test, labeled_pred_lr)}')\n",
    "print(f'AUC Score: {auc(y_test, labeled_pred_lr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-andrews",
   "metadata": {},
   "source": [
    "# Random Forest Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-thailand",
   "metadata": {},
   "source": [
    "### Display K-fold Cross Validation for Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "prepared-butler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>fold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.985906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.910726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.908148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.905302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.903678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.873244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_samples_split  n_estimators  fold       auc\n",
       "0           8                  2           200     1  0.986576\n",
       "0           8                  2           500     1  0.986288\n",
       "0           8                  2           100     1  0.986136\n",
       "0           8                  2           500     5  0.985906\n",
       "0           8                  2            50     1  0.985852\n",
       "..        ...                ...           ...   ...       ...\n",
       "0           1                  2            10     3  0.910726\n",
       "0           1                100            10     3  0.908148\n",
       "0           1                 30            10     2  0.905302\n",
       "0           1                 30            10     3  0.903678\n",
       "0           1                100            10     5  0.873244\n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_results = pd.concat(results_dict['random_forest'])\n",
    "random_forest_results.sort_values(by='auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "confused-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model\n",
      "F1 Score: 0.932\n",
      "AUC Score: 0.9287909569203522\n"
     ]
    }
   ],
   "source": [
    "rfClf = rfClfs(random_state=0, max_depth=8, n_estimators= 200, min_samples_split=2).fit(x_train, y_train)\n",
    "labeled_pred_rfClfs = rfClf.predict(x_test)\n",
    "print('Random Forest Model')\n",
    "print(f'F1 Score: {f1(y_test, labeled_pred_rfClfs)}')\n",
    "print(f'AUC Score: {auc(y_test, labeled_pred_rfClfs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-throat",
   "metadata": {},
   "source": [
    "# Gradient Boosting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-intent",
   "metadata": {},
   "source": [
    "### Display K-fold Cross Validation for Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "alleged-income",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>use_label_encoder</th>\n",
       "      <th>fold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.988103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eval_metric  learning_rate  max_depth  min_child_weight  n_estimators  \\\n",
       "0         auc            0.2          6                 1           100   \n",
       "0         auc            0.2          4                 3           100   \n",
       "0         auc            0.2          6                 1           200   \n",
       "0         auc            0.1          6                 1           200   \n",
       "0         auc            0.2          6                 3           100   \n",
       "0         auc            0.5          4                 3            50   \n",
       "0         auc            0.2          8                 1           100   \n",
       "0         auc            0.2          6                 3           200   \n",
       "0         auc            0.1          6                 3           200   \n",
       "0         auc            0.2          4                 1           200   \n",
       "0         auc            0.2          4                 3           200   \n",
       "0         auc            0.5          4                 3           200   \n",
       "0         auc            0.2          8                 1           200   \n",
       "0         auc            0.5          4                 3           100   \n",
       "0         auc            0.2          6                 1            50   \n",
       "0         auc            0.1          4                 3           200   \n",
       "0         auc            0.1          8                 3           200   \n",
       "0         auc            0.1          6                 1           100   \n",
       "0         auc            0.1          8                 3           100   \n",
       "0         auc            0.2          6                 1            50   \n",
       "0         auc            0.1          8                 1           200   \n",
       "0         auc            0.2          4                 1           100   \n",
       "0         auc            0.5          8                 1           100   \n",
       "0         auc            0.1          4                 1           200   \n",
       "0         auc            0.2          8                 3           200   \n",
       "0         auc            0.2          6                 3            50   \n",
       "0         auc            0.2          8                 3            50   \n",
       "0         auc            0.2          8                 3            50   \n",
       "0         auc            0.2          8                 3           100   \n",
       "0         auc            0.2          8                 1            50   \n",
       "\n",
       "   use_label_encoder  fold       auc  \n",
       "0              False     1  0.989239  \n",
       "0              False     1  0.989041  \n",
       "0              False     1  0.988908  \n",
       "0              False     1  0.988903  \n",
       "0              False     1  0.988886  \n",
       "0              False     1  0.988884  \n",
       "0              False     1  0.988834  \n",
       "0              False     1  0.988799  \n",
       "0              False     1  0.988768  \n",
       "0              False     1  0.988720  \n",
       "0              False     1  0.988692  \n",
       "0              False     1  0.988681  \n",
       "0              False     1  0.988555  \n",
       "0              False     1  0.988550  \n",
       "0              False     1  0.988520  \n",
       "0              False     1  0.988465  \n",
       "0              False     1  0.988463  \n",
       "0              False     1  0.988441  \n",
       "0              False     1  0.988424  \n",
       "0              False     5  0.988422  \n",
       "0              False     1  0.988393  \n",
       "0              False     1  0.988326  \n",
       "0              False     1  0.988193  \n",
       "0              False     1  0.988154  \n",
       "0              False     1  0.988154  \n",
       "0              False     1  0.988145  \n",
       "0              False     5  0.988143  \n",
       "0              False     1  0.988132  \n",
       "0              False     1  0.988128  \n",
       "0              False     5  0.988103  "
      ]
     },
     "execution_count": 947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosting_results = pd.concat(results_dict['gradient_boosting'])\n",
    "gradient_boosting_results.sort_values(by='auc', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "radical-excerpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model\n",
      "F1 Score: 0.9530612244897958\n",
      "AUC Score: 0.9519716622388916\n"
     ]
    }
   ],
   "source": [
    "gbclf = GBClf(random_state=0, max_depth=6, n_estimators= 100, min_child_weight=1, learning_rate=0.200,\n",
    "             use_label_encoder=False, eval_metric='auc').fit(x_train, y_train)\n",
    "labeled_pred_gbclf = gbclf.predict(x_test)\n",
    "print('Gradient Boosting Model')\n",
    "print(f'F1 Score: {f1(y_test, labeled_pred_gbclf)}')\n",
    "print(f'AUC Score: {auc(y_test, labeled_pred_gbclf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-microphone",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-plaza",
   "metadata": {},
   "source": [
    "### Display K-fold Cross Validation for Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "consistent-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>fold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>0.967680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.967338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>0.967248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>0.966450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.966194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>0.965060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>0.965022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.964827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.963424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>0.962099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>4</td>\n",
       "      <td>0.961445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>0.959068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>3</td>\n",
       "      <td>0.957743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors  weights  fold       auc\n",
       "0            9  uniform     1  0.971945\n",
       "0           10  uniform     1  0.971655\n",
       "0            8  uniform     1  0.971110\n",
       "0            7  uniform     1  0.970062\n",
       "0            6  uniform     1  0.969458\n",
       "0            5  uniform     1  0.968833\n",
       "0           10  uniform     4  0.967680\n",
       "0           10  uniform     2  0.967338\n",
       "0            9  uniform     4  0.967248\n",
       "0           10  uniform     5  0.966450\n",
       "0            9  uniform     2  0.966194\n",
       "0            8  uniform     4  0.966137\n",
       "0            6  uniform     2  0.965923\n",
       "0            7  uniform     2  0.965566\n",
       "0            7  uniform     4  0.965060\n",
       "0            9  uniform     5  0.965022\n",
       "0            6  uniform     4  0.964947\n",
       "0            8  uniform     2  0.964827\n",
       "0            4  uniform     1  0.964420\n",
       "0            5  uniform     2  0.963424\n",
       "0            5  uniform     5  0.962586\n",
       "0            8  uniform     5  0.962276\n",
       "0            6  uniform     5  0.962154\n",
       "0            7  uniform     5  0.962108\n",
       "0            5  uniform     4  0.962099\n",
       "0            4  uniform     4  0.961445\n",
       "0            4  uniform     2  0.959068\n",
       "0            8  uniform     3  0.958985\n",
       "0            7  uniform     3  0.958063\n",
       "0            9  uniform     3  0.957743"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_results = pd.concat(results_dict['k-nearest_neighbors'])\n",
    "knn_results.sort_values(by='auc', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "subsequent-membrane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Model\n",
      "F1 Score: 0.9014925373134329\n",
      "AUC Score: 0.8964291295514925\n"
     ]
    }
   ],
   "source": [
    "knn = KNClf(n_neighbors=15, weights='uniform').fit(x_train, y_train)\n",
    "labeled_pred_knn = knn.predict(x_test)\n",
    "print('K-Nearest Neighbors Model')\n",
    "print(f'F1 Score: {f1(y_test, labeled_pred_knn)}')\n",
    "print(f'AUC Score: {auc(y_test, labeled_pred_knn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-aggregate",
   "metadata": {},
   "source": [
    "# Support Vector Machine Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-major",
   "metadata": {},
   "source": [
    "### Display K-fold Cross Validation for Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "placed-newspaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>probability</th>\n",
       "      <th>fold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.977067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.976952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.976504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.971587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.969648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.969452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.965777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.956351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.953027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.951290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.948274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.947171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.944229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.942048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.939450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.934850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.933919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.931236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.930343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.928430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.925697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.903229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.899790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.897598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C  probability  fold       auc\n",
       "0  1000.00         True     2  0.978378\n",
       "0  1000.00         True     5  0.977067\n",
       "0  1000.00         True     4  0.976952\n",
       "0  1000.00         True     1  0.976822\n",
       "0  1000.00         True     3  0.976504\n",
       "0   100.00         True     2  0.971587\n",
       "0   100.00         True     5  0.969648\n",
       "0   100.00         True     4  0.969452\n",
       "0   100.00         True     1  0.966732\n",
       "0   100.00         True     3  0.965777\n",
       "0    10.00         True     5  0.956351\n",
       "0    10.00         True     2  0.955491\n",
       "0    10.00         True     1  0.953062\n",
       "0     5.00         True     5  0.953027\n",
       "0     5.00         True     2  0.951290\n",
       "0     5.00         True     1  0.950815\n",
       "0    10.00         True     4  0.948274\n",
       "0    10.00         True     3  0.947171\n",
       "0     5.00         True     4  0.944229\n",
       "0     5.00         True     3  0.942048\n",
       "0     1.00         True     1  0.941483\n",
       "0     1.00         True     5  0.939450\n",
       "0     0.50         True     1  0.934943\n",
       "0     1.00         True     2  0.934850\n",
       "0     1.00         True     4  0.933919\n",
       "0     0.50         True     5  0.931236\n",
       "0     1.00         True     3  0.930343\n",
       "0     0.50         True     4  0.928430\n",
       "0     0.50         True     2  0.925697\n",
       "0     0.50         True     3  0.925597\n",
       "0     0.01         True     1  0.915215\n",
       "0     0.01         True     4  0.913816\n",
       "0     0.01         True     5  0.903229\n",
       "0     0.01         True     3  0.899790\n",
       "0     0.01         True     2  0.897598"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_results = pd.concat(results_dict['support_vector_machine'])\n",
    "svm_results.sort_values(by='auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "representative-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Model\n",
      "F1 Score: 0.9175769612711022\n",
      "AUC Score: 0.9130723550554773\n"
     ]
    }
   ],
   "source": [
    "svm = SvmClf(C=1000.0, probability=True).fit(x_train, y_train)\n",
    "labeled_pred_svm = svm.predict(x_test)\n",
    "print('Support Vector Machine Model')\n",
    "print(f'F1 Score: {f1(y_test, labeled_pred_svm)}')\n",
    "print(f'AUC Score: {auc(y_test, labeled_pred_svm)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-seattle",
   "metadata": {},
   "source": [
    "# MLP Neural Network Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-locator",
   "metadata": {},
   "source": [
    "### Display K-fold Cross Validation for Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "stunning-temperature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>solver</th>\n",
       "      <th>fold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>5</td>\n",
       "      <td>0.987824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>5</td>\n",
       "      <td>0.986876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>4</td>\n",
       "      <td>0.986432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.986325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>4</td>\n",
       "      <td>0.986070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>4</td>\n",
       "      <td>0.985499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.984941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.984504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>5</td>\n",
       "      <td>0.983731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.982784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>4</td>\n",
       "      <td>0.982662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.982344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>3</td>\n",
       "      <td>0.982300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.982069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2</td>\n",
       "      <td>0.981533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>0.981302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>0.980871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>0.979598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>5</td>\n",
       "      <td>0.979585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>adam</td>\n",
       "      <td>4</td>\n",
       "      <td>0.967429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>3</td>\n",
       "      <td>0.967416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>3</td>\n",
       "      <td>0.966436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>25000</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>5</td>\n",
       "      <td>0.962095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden_layer_sizes  max_iter solver  fold       auc\n",
       "0                  50     25000  lbfgs     5  0.987824\n",
       "0                 100     25000  lbfgs     1  0.987801\n",
       "0                  50     25000  lbfgs     1  0.987635\n",
       "0                  20     25000  lbfgs     1  0.987509\n",
       "0                 150     25000  lbfgs     1  0.987221\n",
       "0                 150     25000  lbfgs     5  0.986876\n",
       "0                 100     25000  lbfgs     4  0.986432\n",
       "0                 150     25000   adam     5  0.986325\n",
       "0                  50     25000  lbfgs     4  0.986070\n",
       "0                 150     25000   adam     1  0.986027\n",
       "0                 100     25000   adam     1  0.985517\n",
       "0                 150     25000  lbfgs     4  0.985499\n",
       "0                  50     25000   adam     5  0.984941\n",
       "0                 100     25000   adam     5  0.984504\n",
       "0                  20     25000   adam     1  0.984109\n",
       "0                  20     25000   adam     5  0.983731\n",
       "0                  50     25000   adam     1  0.983712\n",
       "0                 150     25000  lbfgs     2  0.983381\n",
       "0                  20     25000  lbfgs     2  0.983277\n",
       "0                  20     25000   adam     2  0.982806\n",
       "0                  50     25000   adam     2  0.982802\n",
       "0                 150     25000   adam     4  0.982784\n",
       "0                 100     25000   adam     2  0.982714\n",
       "0                  20     25000  lbfgs     4  0.982662\n",
       "0                 100     25000  lbfgs     3  0.982653\n",
       "0                 100     25000   adam     4  0.982344\n",
       "0                 150     25000  lbfgs     3  0.982300\n",
       "0                 150     25000   adam     2  0.982239\n",
       "0                  50     25000   adam     4  0.982069\n",
       "0                  50     25000  lbfgs     2  0.981533\n",
       "0                  50     25000   adam     3  0.981302\n",
       "0                 150     25000   adam     3  0.980871\n",
       "0                 100     25000   adam     3  0.979598\n",
       "0                 100     25000  lbfgs     5  0.979585\n",
       "0                 100     25000  lbfgs     2  0.975279\n",
       "0                  20     25000   adam     3  0.974642\n",
       "0                  20     25000   adam     4  0.967429\n",
       "0                  20     25000  lbfgs     3  0.967416\n",
       "0                  50     25000  lbfgs     3  0.966436\n",
       "0                  20     25000  lbfgs     5  0.962095"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_nn_results = pd.concat(results_dict['mlp_neural_network'])\n",
    "mlp_nn_results.sort_values(by='auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "finnish-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Neural Network Model\n",
      "F1 Score: 0.9371196754563895\n",
      "AUC Score: 0.9352242537896547\n"
     ]
    }
   ],
   "source": [
    "mlp_nn = MlpClf(hidden_layer_sizes=50, solver='lbfgs', max_iter=25000).fit(x_train, y_train)\n",
    "labeled_pred_mlp_nn = mlp_nn.predict(x_test)\n",
    "print('MLP Neural Network Model')\n",
    "print(f'F1 Score: {f1(y_test, labeled_pred_mlp_nn)}')\n",
    "print(f'AUC Score: {auc(y_test, labeled_pred_mlp_nn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-increase",
   "metadata": {},
   "source": [
    "# Assess Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "vulnerable-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.952083</td>\n",
       "      <td>0.945344</td>\n",
       "      <td>0.960905</td>\n",
       "      <td>0.951972</td>\n",
       "      <td>0.953061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Neural Network</th>\n",
       "      <td>0.935417</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.935224</td>\n",
       "      <td>0.937120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.906615</td>\n",
       "      <td>0.958848</td>\n",
       "      <td>0.928791</td>\n",
       "      <td>0.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.913542</td>\n",
       "      <td>0.886756</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.913072</td>\n",
       "      <td>0.917577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.906001</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.872832</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.901493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.897917</td>\n",
       "      <td>0.895918</td>\n",
       "      <td>0.903292</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.899590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall       AUC        F1\n",
       "Gradient Boosting       0.952083   0.945344  0.960905  0.951972  0.953061\n",
       "MLP Neural Network      0.935417   0.924000  0.950617  0.935224  0.937120\n",
       "Random Forest           0.929167   0.906615  0.958848  0.928791  0.932000\n",
       "Support Vector Machine  0.913542   0.886756  0.950617  0.913072  0.917577\n",
       "Logistic Regression     0.906250   0.892857  0.925926  0.906001  0.909091\n",
       "K-Nearest Neighbors     0.896875   0.872832  0.932099  0.896429  0.901493\n",
       "Decision Tree           0.897917   0.895918  0.903292  0.897849  0.899590"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the performace metrics for all models\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "predictions = [labeled_pred_dtclf, labeled_pred_lr, labeled_pred_rfClfs, labeled_pred_gbclf, labeled_pred_knn, \\\n",
    "              labeled_pred_svm, labeled_pred_mlp_nn]\n",
    "methods = ['Decision Tree', 'Logistic Regression', 'Random Forest', 'Gradient Boosting', 'K-Nearest Neighbors', \\\n",
    "          'Support Vector Machine', 'MLP Neural Network']\n",
    "performance = pd.DataFrame({'Accuracy' : [accuracy(y_test, m) for m in predictions],\n",
    "                            'Precision' : [precision(y_test, m) for m in predictions],\n",
    "                            'Recall' : [recall(y_test, m) for m in predictions],\n",
    "                            'AUC' : [auc(y_test, m) for m in predictions], \n",
    "                            'F1' : [f1(y_test, m) for m in predictions]}, index=methods)\n",
    "performance.sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-activation",
   "metadata": {},
   "source": [
    "# Create a Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "rural-schedule",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "importances = rfClf.feature_importances_\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "std = np.std([\n",
    "    tree.feature_importances_ for tree in rfClf.estimators_], axis=0)\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-salad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inst_414",
   "language": "python",
   "name": "inst_414"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
